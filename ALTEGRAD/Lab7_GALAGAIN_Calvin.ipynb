{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":83287,"status":"ok","timestamp":1671660580921,"user":{"displayName":"Calvin GALAGAIN","userId":"00831497643848271461"},"user_tz":-60},"id":"jBou9nkTyDT_","outputId":"27293bd5-9caa-4aea-e1f8-1b3c7a498058"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting graphein\n","  Downloading graphein-1.5.2.tar.gz (185 kB)\n","\u001b[K     |████████████████████████████████| 185 kB 6.8 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting bioservices\u003e=1.10.0\n","  Downloading bioservices-1.10.4.tar.gz (197 kB)\n","\u001b[K     |████████████████████████████████| 197 kB 66.4 MB/s \n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from graphein) (2.8.8)\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Requirement already satisfied: xarray in /usr/local/lib/python3.8/dist-packages (from graphein) (2022.12.0)\n","Collecting deepdiff\n","  Downloading deepdiff-6.2.2-py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 1.9 MB/s \n","\u001b[?25hCollecting rich-click\n","  Downloading rich_click-1.6.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: multipledispatch in /usr/local/lib/python3.8/dist-packages (from graphein) (0.6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from graphein) (1.21.6)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from graphein) (5.5.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from graphein) (1.0.2)\n","Collecting biopandas\u003e=0.4.1\n","  Downloading biopandas-0.4.1-py2.py3-none-any.whl (878 kB)\n","\u001b[K     |████████████████████████████████| 878 kB 102.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from graphein) (4.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from graphein) (4.64.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from graphein) (1.3.5)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from graphein) (1.10.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from graphein) (1.7.3)\n","Collecting biopython\n","  Downloading biopython-1.80-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 7.1 MB/s \n","\u001b[?25hCollecting pyyaml\u003c6.*,\u003e=5.1\n","  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n","\u001b[K     |████████████████████████████████| 662 kB 86.8 MB/s \n","\u001b[?25hCollecting matplotlib\u003e=3.4.3\n","  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n","\u001b[K     |████████████████████████████████| 9.4 MB 92.5 MB/s \n","\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from graphein) (0.11.2)\n","Collecting loguru\n","  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 7.5 MB/s \n","\u001b[?25hCollecting rich\n","  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n","\u001b[K     |████████████████████████████████| 237 kB 88.3 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from biopandas\u003e=0.4.1-\u003egraphein) (57.4.0)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.8/dist-packages (from bioservices\u003e=1.10.0-\u003egraphein) (1.4.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bioservices\u003e=1.10.0-\u003egraphein) (4.6.3)\n","Collecting colorlog\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Collecting easydev\u003e=0.12.0\n","  Downloading easydev-0.12.0.tar.gz (47 kB)\n","\u001b[K     |████████████████████████████████| 47 kB 5.9 MB/s \n","\u001b[?25hCollecting grequests\n","  Downloading grequests-0.6.0-py3-none-any.whl (5.2 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from bioservices\u003e=1.10.0-\u003egraphein) (2.23.0)\n","Collecting requests_cache\n","  Downloading requests_cache-0.9.7-py3-none-any.whl (48 kB)\n","\u001b[K     |████████████████████████████████| 48 kB 6.6 MB/s \n","\u001b[?25hCollecting suds-community\u003e=0.7\n","  Downloading suds_community-1.1.2-py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 90.1 MB/s \n","\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from bioservices\u003e=1.10.0-\u003egraphein) (4.9.2)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from bioservices\u003e=1.10.0-\u003egraphein) (1.14.1)\n","Collecting xmltodict\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from easydev\u003e=0.12.0-\u003ebioservices\u003e=1.10.0-\u003egraphein) (4.8.0)\n","Collecting contourpy\u003e=1.0.1\n","  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n","\u001b[K     |████████████████████████████████| 295 kB 87.2 MB/s \n","\u001b[?25hRequirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.4.3-\u003egraphein) (7.1.2)\n","Requirement already satisfied: pyparsing\u003e=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.4.3-\u003egraphein) (3.0.9)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.4.3-\u003egraphein) (0.11.0)\n","Collecting fonttools\u003e=4.22.0\n","  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n","\u001b[K     |████████████████████████████████| 965 kB 86.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.4.3-\u003egraphein) (21.3)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.4.3-\u003egraphein) (2.8.2)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.4.3-\u003egraphein) (1.4.4)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas-\u003egraphein) (2022.6)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib\u003e=3.4.3-\u003egraphein) (1.15.0)\n","Collecting ordered-set\u003c4.2.0,\u003e=4.0.2\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Collecting gevent\n","  Downloading gevent-22.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 80.4 MB/s \n","\u001b[?25hRequirement already satisfied: greenlet\u003e=2.0.0 in /usr/local/lib/python3.8/dist-packages (from gevent-\u003egrequests-\u003ebioservices\u003e=1.10.0-\u003egraphein) (2.0.1)\n","Collecting zope.event\n","  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n","Collecting zope.interface\n","  Downloading zope.interface-5.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (261 kB)\n","\u001b[K     |████████████████████████████████| 261 kB 91.8 MB/s \n","\u001b[?25hRequirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect-\u003eeasydev\u003e=0.12.0-\u003ebioservices\u003e=1.10.0-\u003egraphein) (0.7.0)\n","Requirement already satisfied: tenacity\u003e=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly-\u003egraphein) (8.1.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests-\u003ebioservices\u003e=1.10.0-\u003egraphein) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003ebioservices\u003e=1.10.0-\u003egraphein) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-\u003ebioservices\u003e=1.10.0-\u003egraphein) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-\u003ebioservices\u003e=1.10.0-\u003egraphein) (2022.12.7)\n","Collecting url-normalize\u003e=1.4\n","  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n","Collecting cattrs\u003e=22.2\n","  Downloading cattrs-22.2.0-py3-none-any.whl (35 kB)\n","Collecting urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 96.0 MB/s \n","\u001b[?25hRequirement already satisfied: attrs\u003e=21.2 in /usr/local/lib/python3.8/dist-packages (from requests_cache-\u003ebioservices\u003e=1.10.0-\u003egraphein) (22.1.0)\n","Collecting exceptiongroup\n","  Downloading exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich-\u003egraphein) (2.6.1)\n","Collecting commonmark\u003c0.10.0,\u003e=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 9.8 MB/s \n","\u001b[?25hRequirement already satisfied: click\u003e=7 in /usr/local/lib/python3.8/dist-packages (from rich-click-\u003egraphein) (7.1.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn-\u003egraphein) (3.1.0)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn-\u003egraphein) (1.2.0)\n","Building wheels for collected packages: graphein, bioservices, easydev, wget\n","  Building wheel for graphein (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for graphein: filename=graphein-1.5.2-py3-none-any.whl size=199494 sha256=5b2660540ce4b56064a56704ae36b94cab9989107b3d038b60ff1515861400ab\n","  Stored in directory: /root/.cache/pip/wheels/cf/8d/50/155cb33cbbb73b5817ab84f4ed0859ad6381aa297749a0a31d\n","  Building wheel for bioservices (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bioservices: filename=bioservices-1.10.4-py3-none-any.whl size=230587 sha256=ea47fc8a39d28a95c5e097ef591f148814a599c8fe35900870ec26f1d8563c37\n","  Stored in directory: /root/.cache/pip/wheels/c6/0e/cd/c43122ec1b7a34d6ae165695f4520ae18d58cac45b75e197a8\n","  Building wheel for easydev (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for easydev: filename=easydev-0.12.0-py3-none-any.whl size=64232 sha256=0920b6b3a86a074ed9b76eb765f8a31c4a07da379b85b601cc8a26a21ed62843\n","  Stored in directory: /root/.cache/pip/wheels/e2/47/9f/de01f291cfde341b33383bcf1292b17d64c700d4a12b318a7d\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=1d3faca9a6c69affedcb465a0e70bcdfea06a5ef6eb6df77748729d8ba176b3f\n","  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n","Successfully built graphein bioservices easydev wget\n","Installing collected packages: zope.interface, zope.event, urllib3, exceptiongroup, url-normalize, gevent, fonttools, contourpy, commonmark, colorlog, colorama, cattrs, xmltodict, suds-community, rich, requests-cache, ordered-set, matplotlib, grequests, easydev, wget, rich-click, pyyaml, loguru, deepdiff, bioservices, biopython, biopandas, graphein\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","Successfully installed biopandas-0.4.1 biopython-1.80 bioservices-1.10.4 cattrs-22.2.0 colorama-0.4.6 colorlog-6.7.0 commonmark-0.9.1 contourpy-1.0.6 deepdiff-6.2.2 easydev-0.12.0 exceptiongroup-1.0.4 fonttools-4.38.0 gevent-22.10.2 graphein-1.5.2 grequests-0.6.0 loguru-0.6.0 matplotlib-3.6.2 ordered-set-4.1.0 pyyaml-5.4.1 requests-cache-0.9.7 rich-12.6.0 rich-click-1.6.0 suds-community-1.1.2 url-normalize-1.4.3 urllib3-1.25.11 wget-3.2 xmltodict-0.13.0 zope.event-4.6 zope.interface-5.5.2\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[K     |████████████████████████████████| 79.9 MB 131 kB/s \n","\u001b[?25hInstalling collected packages: kaleido\n","Successfully installed kaleido-0.2.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting biovec\n","  Downloading biovec-0.2.7.tar.gz (5.9 kB)\n","Collecting gensim==3.4.0\n","  Downloading gensim-3.4.0.tar.gz (22.2 MB)\n","\u001b[K     |████████████████████████████████| 22.2 MB 6.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=2.0.0 in /usr/local/lib/python3.8/dist-packages (from biovec) (4.64.1)\n","Collecting pyfasta==0.5.2\n","  Downloading pyfasta-0.5.2.tar.gz (19 kB)\n","Requirement already satisfied: numpy\u003e=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim==3.4.0-\u003ebiovec) (1.21.6)\n","Requirement already satisfied: scipy\u003e=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim==3.4.0-\u003ebiovec) (1.7.3)\n","Requirement already satisfied: six\u003e=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim==3.4.0-\u003ebiovec) (1.15.0)\n","Requirement already satisfied: smart_open\u003e=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim==3.4.0-\u003ebiovec) (6.3.0)\n","Building wheels for collected packages: biovec, gensim, pyfasta\n","  Building wheel for biovec (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for biovec: filename=biovec-0.2.7-py3-none-any.whl size=3464 sha256=e0f38f4cd7ada9adb66ad9b0b0711b3c71a2927c11ccc519258e85e7c0eba30e\n","  Stored in directory: /root/.cache/pip/wheels/9f/c6/89/87aaf7b2d49ed06c0c8843e576bea4dddbb480b49a5a9f9088\n","  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gensim: filename=gensim-3.4.0-cp38-cp38-linux_x86_64.whl size=23477340 sha256=1801d1a6af73b4ed81c3513dd91f9a62e10406f189d3181372832ff6ac2982fd\n","  Stored in directory: /root/.cache/pip/wheels/b4/a4/71/a301cdb2b7d5d31525936fcb8dcd9a5f144578d047407f7cf9\n","  Building wheel for pyfasta (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyfasta: filename=pyfasta-0.5.2-py3-none-any.whl size=14237 sha256=2a5d95ffe4c5263b44a89cfdddd2672657acb18590295c5ef12998fc0fc9b041\n","  Stored in directory: /root/.cache/pip/wheels/60/3a/d7/9739d86ad827f1dfcd9da43c9fd38a03c6d4a26d2ce25e440d\n","Successfully built biovec gensim pyfasta\n","Installing collected packages: pyfasta, gensim, biovec\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed biovec-0.2.7 gensim-3.4.0 pyfasta-0.5.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch3d\n","  Downloading pytorch3d-0.3.0-cp38-cp38-manylinux1_x86_64.whl (30.0 MB)\n","\u001b[K     |████████████████████████████████| 30.0 MB 95 kB/s \n","\u001b[?25hRequirement already satisfied: torchvision\u003e=0.4 in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.14.0+cu116)\n","Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision\u003e=0.4-\u003epytorch3d) (1.21.6)\n","Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision\u003e=0.4-\u003epytorch3d) (1.13.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision\u003e=0.4-\u003epytorch3d) (4.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision\u003e=0.4-\u003epytorch3d) (2.23.0)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision\u003e=0.4-\u003epytorch3d) (7.1.2)\n","Collecting yacs\u003e=0.1.6\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore-\u003epytorch3d) (5.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore-\u003epytorch3d) (4.64.1)\n","Requirement already satisfied: termcolor\u003e=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore-\u003epytorch3d) (2.1.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore-\u003epytorch3d) (0.8.10)\n","Collecting iopath\u003e=0.1.7\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n","\u001b[?25hCollecting portalocker\n","  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etorchvision\u003e=0.4-\u003epytorch3d) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etorchvision\u003e=0.4-\u003epytorch3d) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etorchvision\u003e=0.4-\u003epytorch3d) (1.25.11)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etorchvision\u003e=0.4-\u003epytorch3d) (2022.12.7)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=fe958c07469c52e0470693136f983170ecd0a2fb979a10cb18bea3feda91e6f8\n","  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=4870b7b7e26186eae37171845afa7e26e444a50736adac4506d930de4b364071\n","  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n","Successfully built fvcore iopath\n","Installing collected packages: portalocker, yacs, iopath, fvcore, pytorch3d\n","Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.6.0 pytorch3d-0.3.0 yacs-0.1.8\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting matplotlib==3.1.3\n","  Downloading matplotlib-3.1.3-cp38-cp38-manylinux1_x86_64.whl (13.1 MB)\n","\u001b[K     |████████████████████████████████| 13.1 MB 8.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (3.0.9)\n","Requirement already satisfied: numpy\u003e=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.21.6)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (2.8.2)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (0.11.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.4.4)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil\u003e=2.1-\u003ematplotlib==3.1.3) (1.15.0)\n","Installing collected packages: matplotlib\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.6.2\n","    Uninstalling matplotlib-3.6.2:\n","      Successfully uninstalled matplotlib-3.6.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","graphein 1.5.2 requires matplotlib\u003e=3.4.3, but you have matplotlib 3.1.3 which is incompatible.\u001b[0m\n","Successfully installed matplotlib-3.1.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install graphein\n","!pip install -U kaleido\n","!pip install biovec\n","!pip install pytorch3d\n","!pip install matplotlib==3.1.3"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671660580921,"user":{"displayName":"Calvin GALAGAIN","userId":"00831497643848271461"},"user_tz":-60},"id":"hOkM9FHRRyu8"},"outputs":[],"source":["\"\"\"\n","Learning on Sets / Learning with Proteins - ALTEGRAD - Dec 2022\n","\"\"\"\n","\n","import numpy as np\n","\n","\n","def create_train_dataset():\n","    n_train = 100000\n","    max_train_card = 10\n","\n","    ############## Task 1\n","    \n","    ##################\n","    # your code here #\n","    X_train = np.zeros((n_train, max_train_card))\n","    y_train = np.zeros(n_train)\n","    for i in range(n_train):\n","      card = np.random.randint(1, max_train_card+1)\n","      X_train[i, -card:] = np.random.randint(1, max_train_card+1, size = card)\n","      y_train[i] = np.sum(X_train[i, :])\n","      \n","    ##################\n","\n","    return X_train, y_train\n","\n","\n","def create_test_dataset():\n","    \n","    ############## Task 2\n","    \n","    ##################\n","    # your code here #\n","    n_test = 200000\n","    min_test_card = 5\n","    max_test_card = 101\n","    step_test_card = 5\n","    cards = range(min_test_card, max_test_card, step_test_card)\n","    n_samples_per_card = n_test // len(cards)\n","\n","    X_test = list()\n","    y_test = list()\n","\n","    for card in cards:\n","      X = np.random.randint(1, 11, size=(n_samples_per_card, card))\n","      X_test.append(X)\n","      y_test.append(np.sum(X, axis=1))\n","    ##################\n","\n","    return X_test, y_test"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2432,"status":"ok","timestamp":1671660583350,"user":{"displayName":"Calvin GALAGAIN","userId":"00831497643848271461"},"user_tz":-60},"id":"l2a_RusrRo7E"},"outputs":[],"source":["\"\"\"\n","Learning on Sets / Learning with Proteins - ALTEGRAD - Dec 2022\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","\n","class DeepSets(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim):\n","        super(DeepSets, self).__init__()\n","        self.embedding = nn.Embedding(input_dim, embedding_dim)\n","        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, 1)\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, x):\n","        \n","        ############## Task 3\n","    \n","        ##################\n","        # your code here #\n","\n","        x = self.embedding(x)\n","        x = self.tanh(self.fc1(x))\n","        x = torch.sum(x, dim=1)\n","        x = self.fc2(x)\n","        ##################\n","        \n","        return x.squeeze()\n","\n","\n","class LSTM(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim):\n","        super(LSTM, self).__init__()\n","\n","        self.embedding = nn.Embedding(input_dim, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, 1)\n","\n","    def forward(self, x):\n","        \n","        ############## Task 4\n","    \n","        ##################\n","        # your code here #\n","        x = self.embedding(x)\n","        _, (x, _) = self.lstm(x)\n","        x = self.fc(x)\n","        ##################\n","        \n","        return x.squeeze()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130302,"status":"ok","timestamp":1671660714685,"user":{"displayName":"Calvin GALAGAIN","userId":"00831497643848271461"},"user_tz":-60},"id":"t9m7gJgUZRVz","outputId":"772d48c7-733f-41da-f981-c254e26338ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0001 loss_train: 0.8889 time: 6.0997s\n","Epoch: 0002 loss_train: 0.0604 time: 2.5232s\n","Epoch: 0003 loss_train: 0.0486 time: 2.5315s\n","Epoch: 0004 loss_train: 0.0438 time: 2.4882s\n","Epoch: 0005 loss_train: 0.0378 time: 2.4814s\n","Epoch: 0006 loss_train: 0.0353 time: 2.5181s\n","Epoch: 0007 loss_train: 0.0326 time: 2.5107s\n","Epoch: 0008 loss_train: 0.0272 time: 2.5057s\n","Epoch: 0009 loss_train: 0.0279 time: 2.5216s\n","Epoch: 0010 loss_train: 0.0270 time: 2.5067s\n","Epoch: 0011 loss_train: 0.0276 time: 2.5826s\n","Epoch: 0012 loss_train: 0.0262 time: 2.5118s\n","Epoch: 0013 loss_train: 0.0254 time: 2.4822s\n","Epoch: 0014 loss_train: 0.0254 time: 2.4966s\n","Epoch: 0015 loss_train: 0.0267 time: 2.5015s\n","Epoch: 0016 loss_train: 0.0244 time: 2.4739s\n","Epoch: 0017 loss_train: 0.0246 time: 2.4803s\n","Epoch: 0018 loss_train: 0.0250 time: 2.4853s\n","Epoch: 0019 loss_train: 0.0259 time: 2.4890s\n","Epoch: 0020 loss_train: 0.0265 time: 2.4901s\n","Finished training for DeepSets model\n","\n","Epoch: 0001 loss_train: 6.2159 time: 4.3520s\n","Epoch: 0002 loss_train: 0.2536 time: 3.4350s\n","Epoch: 0003 loss_train: 0.1390 time: 3.4414s\n","Epoch: 0004 loss_train: 0.1062 time: 3.4149s\n","Epoch: 0005 loss_train: 0.0966 time: 3.4573s\n","Epoch: 0006 loss_train: 0.0836 time: 3.4558s\n","Epoch: 0007 loss_train: 0.0817 time: 3.4660s\n","Epoch: 0008 loss_train: 0.0808 time: 3.6475s\n","Epoch: 0009 loss_train: 0.0773 time: 3.4862s\n","Epoch: 0010 loss_train: 0.0722 time: 3.4662s\n","Epoch: 0011 loss_train: 0.0734 time: 3.4674s\n","Epoch: 0012 loss_train: 0.0716 time: 3.4210s\n","Epoch: 0013 loss_train: 0.0694 time: 3.4212s\n","Epoch: 0014 loss_train: 0.0696 time: 3.4292s\n","Epoch: 0015 loss_train: 0.0679 time: 3.4327s\n","Epoch: 0016 loss_train: 0.0677 time: 3.5389s\n","Epoch: 0017 loss_train: 0.0661 time: 3.4419s\n","Epoch: 0018 loss_train: 0.0667 time: 3.4533s\n","Epoch: 0019 loss_train: 0.0663 time: 3.4586s\n","Epoch: 0020 loss_train: 0.0655 time: 3.5354s\n","Finished training for LSTM model\n"]}],"source":["\"\"\"\n","Learning on Sets / Learning with Proteins - ALTEGRAD - Dec 2022\n","\"\"\"\n","\n","import time\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","\n","# from utils import create_train_dataset\n","# from models import DeepSets, LSTM\n","\n","\n","# Initializes device\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# Hyperparameters\n","epochs = 20\n","batch_size = 64\n","embedding_dim = 128\n","hidden_dim = 64\n","learning_rate = 0.001\n","\n","# Generates training data\n","X_train, y_train = create_train_dataset()\n","n_train = 100000\n","n_digits = 11\n","\n","# Initializes DeepSets model and optimizer\n","deepsets = DeepSets(n_digits, embedding_dim, hidden_dim).to(device)\n","optimizer = optim.Adam(deepsets.parameters(), lr=learning_rate)\n","loss_function = nn.L1Loss()\n","\n","# Trains the DeepSets model\n","for epoch in range(epochs):\n","    t = time.time()\n","    deepsets.train()\n","     \n","    train_loss = 0\n","    count = 0\n","    idx = np.random.permutation(n_train)\n","    for i in range(0, n_train, batch_size):\n","        \n","        ############## Task 5\n","    \n","        ##################\n","        # your code here #\n","        x_batch = X_train[idx[i: min(i+batch_size, n_train)], :]\n","        y_batch = y_train[idx[i: min(i+batch_size, n_train)]]\n","\n","        x_batch = torch.LongTensor(x_batch).to(device)\n","        y_batch = torch.FloatTensor(y_batch).to(device)\n","        ##################\n","        \n","        optimizer.zero_grad()\n","        output = deepsets(x_batch)\n","        loss = loss_function(output, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * output.size(0)\n","        count += output.size(0)\n","    \n","    print('Epoch: {:04d}'.format(epoch+1),\n","          'loss_train: {:.4f}'.format(train_loss / count),\n","          'time: {:.4f}s'.format(time.time() - t))\n","\n","# Stores DeepSets model into disk\n","torch.save({\n","    'state_dict': deepsets.state_dict(),\n","    'optimizer' : optimizer.state_dict(),\n","}, 'model_deepsets.pth.tar')\n","\n","print(\"Finished training for DeepSets model\")\n","print()\n","\n","# Initializes LSTM model and optimizer\n","lstm = LSTM(n_digits, embedding_dim, hidden_dim).to(device)\n","optimizer = optim.Adam(lstm.parameters(), lr=learning_rate)\n","loss_function = nn.L1Loss()\n","\n","# Trains the LSTM model\n","for epoch in range(epochs):\n","    t = time.time()\n","    lstm.train()\n","     \n","    train_loss = 0\n","    count = 0\n","    idx = np.random.permutation(n_train)\n","    for i in range(0, n_train, batch_size):\n","    \n","        ############## Task 5\n","        \n","        ##################\n","        # your code here #\n","        x_batch = X_train[idx[i: min(i+batch_size, n_train)], :]\n","        y_batch = y_train[idx[i: min(i+batch_size, n_train)]]\n","\n","        x_batch = torch.LongTensor(x_batch).to(device)\n","        y_batch = torch.FloatTensor(y_batch).to(device)\n","        ##################\n","        \n","        optimizer.zero_grad()\n","        output = lstm(x_batch)\n","        loss = loss_function(output, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * output.size(0)\n","        count += output.size(0)\n","    \n","    print('Epoch: {:04d}'.format(epoch+1),\n","          'loss_train: {:.4f}'.format(train_loss / count),\n","          'time: {:.4f}s'.format(time.time() - t))\n","\n","# Stores LSTM model into disk\n","torch.save({\n","    'state_dict': lstm.state_dict(),\n","    'optimizer' : optimizer.state_dict(),\n","}, 'model_lstm.pth.tar')\n","\n","print(\"Finished training for LSTM model\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"executionInfo":{"elapsed":3959,"status":"ok","timestamp":1671660718634,"user":{"displayName":"Calvin GALAGAIN","userId":"00831497643848271461"},"user_tz":-60},"id":"cgCLMb5Uc0Ni","outputId":"2b021d12-e088-4e00-9b7c-3c11386d17df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading DeepSets checkpoint!\n","Loading LSTM checkpoint!\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["\"\"\"\n","Learning on Sets / Learning with Proteins - ALTEGRAD - Dec 2022\n","\"\"\"\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, mean_absolute_error\n","import torch\n","\n","# from utils import create_test_dataset\n","# from models import DeepSets, LSTM\n","\n","# Initializes device\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# Hyperparameters\n","batch_size = 64\n","embedding_dim = 128\n","hidden_dim = 64\n","\n","# Generates test data\n","X_test, y_test = create_test_dataset()\n","cards = [X_test[i].shape[1] for i in range(len(X_test))]\n","n_samples_per_card = X_test[0].shape[0]\n","n_digits = 11\n","\n","# Retrieves DeepSets model\n","deepsets = DeepSets(n_digits, embedding_dim, hidden_dim).to(device)\n","print(\"Loading DeepSets checkpoint!\")\n","checkpoint = torch.load('model_deepsets.pth.tar')\n","deepsets.load_state_dict(checkpoint['state_dict'])\n","deepsets.eval()\n","\n","# Retrieves LSTM model\n","lstm = LSTM(n_digits, embedding_dim, hidden_dim).to(device)\n","print(\"Loading LSTM checkpoint!\")\n","checkpoint = torch.load('model_lstm.pth.tar')\n","lstm.load_state_dict(checkpoint['state_dict'])\n","lstm.eval()\n","\n","# Dict to store the results\n","results = {'deepsets': {'acc':[], 'mae':[]}, 'lstm': {'acc':[], 'mae':[]}}\n","\n","for i in range(len(cards)):\n","    y_pred_deepsets = list()\n","    y_pred_lstm = list()\n","    for j in range(0, n_samples_per_card, batch_size):\n","        \n","        ############## Task 6\n","    \n","        ##################\n","        # your code here #\n","        x_batch = X_test[i][j:min(j+batch_size, n_samples_per_card), :]\n","        y_batch = y_test[i][j:min(j+batch_size, n_samples_per_card)]\n","\n","        x_batch = torch.LongTensor(x_batch).to(device)\n","        y_batch = torch.FloatTensor(y_batch).to(device)\n","\n","        output_deepsets = deepsets(x_batch)\n","        y_pred_deepsets.append(output_deepsets)\n","\n","        output_lstm = lstm(x_batch)\n","        y_pred_lstm.append(output_lstm)\n","        ##################\n","        \n","    y_pred_deepsets = torch.cat(y_pred_deepsets)\n","    y_pred_deepsets = y_pred_deepsets.detach().cpu().numpy()\n","    \n","    acc_deepsets = accuracy_score(y_test[i], np.round(y_pred_deepsets)) #your code here\n","    mae_deepsets = mean_absolute_error(y_test[i], y_pred_deepsets)    #your code here\n","    results['deepsets']['acc'].append(acc_deepsets)\n","    results['deepsets']['mae'].append(mae_deepsets)\n","    \n","    y_pred_lstm = torch.cat(y_pred_lstm)\n","    y_pred_lstm = y_pred_lstm.detach().cpu().numpy()\n","    \n","    acc_lstm = accuracy_score(y_test[i], np.round(y_pred_lstm))#your code here\n","    mae_lstm = mean_absolute_error(y_test[i], y_pred_lstm) #your code here\n","    results['lstm']['acc'].append(acc_lstm)\n","    results['lstm']['mae'].append(mae_lstm)\n","\n","\n","############## Task 7\n","    \n","##################\n","# your code here #\n","plt.plot(cards, results[\"deepsets\"][\"acc\"], \"-o\", label = \"DeepSets\")\n","plt.plot(cards, results[\"lstm\"][\"acc\"], \"-o\", label = \"LSTM\")\n","plt.xlabel(\"cardinality\")\n","plt.ylabel(\"accuracy\")\n","plt.legend()\n","plt.show()\n","##################"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":11443,"status":"ok","timestamp":1671660730075,"user":{"displayName":"Calvin GALAGAIN","userId":"00831497643848271461"},"user_tz":-60},"id":"mK8JBpUjvKNQ","outputId":"e75d9aee-5e53-4a9f-8276-76a087191e12"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:graphein.protein.visualisation:To use the Graphein submodule graphein.protein.visualisation, you need to install: pytorch3d \n","pytorch3d cannot be installed via pip\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3aec62271aee41b08a463fe6c4b04e2b","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e/usr/local/lib/python3.8/dist-packages/biopandas/pdb/pandas_pdb.py:681: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: \n","https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  idxs[\"end_idx\"] = ends.line_idx.values\n","\u003c/pre\u003e\n"],"text/plain":["/usr/local/lib/python3.8/dist-packages/biopandas/pdb/pandas_pdb.py:681: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: \n","https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  idxs[\"end_idx\"] = ends.line_idx.values\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003c/pre\u003e\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\n","\u003c/pre\u003e\n"],"text/plain":["\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Number of nodes: 837\n","Number of edges: 4258\n","Max degree: 25\n","Min degree: 2\n","Mean degree: 10.174432497013143\n","Median degree: 10.0\n"]}],"source":["\"\"\"\n","Learning on Sets / Learning with Proteins - ALTEGRAD - Dec 2022\n","\"\"\"\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from functools import partial\n","\n","from graphein.protein.config import ProteinGraphConfig\n","from graphein.protein.graphs import construct_graph\n","from graphein.protein.visualisation import plot_protein_structure_graph, plotly_protein_structure_graph\n","from graphein.protein.analysis import plot_degree_by_residue_type, plot_edge_type_distribution, plot_residue_composition\n","from graphein.protein.edges.distance import add_peptide_bonds, add_hydrogen_bond_interactions, add_disulfide_interactions, add_ionic_interactions, add_aromatic_interactions, add_aromatic_sulphur_interactions, add_cation_pi_interactions, add_distance_threshold, add_k_nn_edges\n","from graphein.protein.features.nodes.amino_acid import amino_acid_one_hot, expasy_protein_scale, meiler_embedding\n","from graphein.protein.utils import download_alphafold_structure\n","\n","# Configuration object for graph construction\n","config = ProteinGraphConfig(**{\"node_metadata_functions\": [amino_acid_one_hot, \n","                                                           expasy_protein_scale,\n","                                                           meiler_embedding],\n","                               \"edge_construction_functions\": [add_peptide_bonds,\n","                                                  add_aromatic_interactions,\n","                                                  add_hydrogen_bond_interactions,\n","                                                  add_disulfide_interactions,\n","                                                  add_ionic_interactions,\n","                                                  add_aromatic_sulphur_interactions,\n","                                                  add_cation_pi_interactions,\n","                                                  partial(add_distance_threshold, long_interaction_threshold=5, threshold=10.),\n","                                                  partial(add_k_nn_edges, k=3, long_interaction_threshold=2)],\n","                               })\n","\n","PDB_CODE = \"Q5VSL9\"\n","\n","\n","############## Task 8\n","    \n","##################\n","# your code here #\n","protein_path  = download_alphafold_structure(PDB_CODE, aligned_score=False)\n","G = construct_graph(pdb_path=protein_path, config=config)\n","##################\n","\n","# Print number of nodes and number of edges\n","print('Number of nodes:', G.number_of_nodes())\n","print('Number of edges:', G.number_of_edges())\n","\n","\n","############## Task 9\n","\n","##################\n","# your code here #\n","degree_seq = [G.degree(node) for node in G.nodes()]\n","print('Max degree:', max(degree_seq))\n","print('Min degree:', min(degree_seq))\n","print('Mean degree:', np.mean(degree_seq))\n","print('Median degree:', np.median(degree_seq))\n","\n","p = plot_degree_by_residue_type(G)\n","p.write_image(\"degree_by_residue_type.pdf\")\n","\n","p = plot_edge_type_distribution(G)\n","p.write_image('edge_type_distribution.pdf')\n","\n","p = plot_residue_composition(G)\n","p.write_image('plot_residue_composition.pdf')\n","\n","p = plotly_protein_structure_graph(G)\n","p.write_image('protein_structure_graph.pdf')\n","##################"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1671660730076,"user":{"displayName":"Calvin GALAGAIN","userId":"00831497643848271461"},"user_tz":-60},"id":"8SWFWT7D5bUw"},"outputs":[],"source":["\"\"\"\n","Learning on Sets / Learning with Proteins - ALTEGRAD - Dec 2022\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class GNN(nn.Module):\n","    \"\"\"\n","    Simple message passing model that consists of 2 message passing layers\n","    and the sum aggregation function\n","    \"\"\"\n","    def __init__(self, input_dim, hidden_dim, dropout, n_class):\n","        super(GNN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n","        self.fc4 = nn.Linear(hidden_dim, n_class)\n","        self.bn = nn.BatchNorm1d(hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x_in, adj, idx):\n","        \n","        ############## Task 10\n","    \n","        ##################\n","        # your code here #        \n","        adj = torch.eye(len(adj), device=adj.device) + adj\n","\n","        x = self.fc1(x_in)\n","        x = self.relu(torch.mm(adj, x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        ##################\n","        \n","        # sum aggregator\n","        idx = idx.unsqueeze(1).repeat(1, x.size(1))\n","        out = torch.zeros(torch.max(idx)+1, x.size(1)).to(x_in.device)\n","        out = out.scatter_add_(0, idx, x)\n","        \n","        ##################\n","        # your code here #\n","        out = self.bn(out)\n","        out = self.relu(self.fc3(out))\n","        out = self.dropout(out)\n","        out = self.fc4(out)\n","        ##################\n","\n","        return F.log_softmax(out, dim=1)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1671660730076,"user":{"displayName":"Calvin GALAGAIN","userId":"00831497643848271461"},"user_tz":-60},"id":"0JsPQejkDOF4"},"outputs":[],"source":["\"\"\"\n","Learning on Sets / Learning with Proteins - ALTEGRAD - Dec 2022\n","\"\"\"\n","\n","import numpy as np\n","import scipy.sparse as sp\n","\n","import torch\n","\n","def load_data(): \n","    \"\"\"\n","    Function that loads graphs\n","    \"\"\"  \n","    graph_indicator = np.loadtxt(\"/content/drive/MyDrive/MVA/ALTEGRAD/rendu/Lab7/code/data/graph_indicator.txt\", dtype=np.int64)\n","    _,graph_size = np.unique(graph_indicator, return_counts=True)\n","    \n","    edges = np.loadtxt(\"/content/drive/MyDrive/MVA/ALTEGRAD/rendu/Lab7/code/data/edgelist.txt\", dtype=np.int64, delimiter=\",\")\n","    A = sp.csr_matrix((np.ones(edges.shape[0]), (edges[:,0], edges[:,1])), shape=(graph_indicator.size, graph_indicator.size))\n","    A += A.T\n","    \n","    x = np.loadtxt(\"/content/drive/MyDrive/MVA/ALTEGRAD/rendu/Lab7/code/data/node_attributes.txt\", delimiter=\",\")\n","    edge_attr = np.loadtxt(\"/content/drive/MyDrive/MVA/ALTEGRAD/rendu/Lab7/code/data/edge_attributes.txt\", delimiter=\",\")\n","    graph_labels = np.loadtxt(\"/content/drive/MyDrive/MVA/ALTEGRAD/rendu/Lab7/code/data/graph_labels.txt\", dtype=np.int64)\n","    \n","    adj = []\n","    features = []\n","    edge_features = []\n","    idx_n = 0\n","    idx_m = 0\n","    for i in range(graph_size.size):\n","        adj.append(A[idx_n:idx_n+graph_size[i],idx_n:idx_n+graph_size[i]])\n","        edge_features.append(edge_attr[idx_m:idx_m+adj[i].nnz,:])\n","        features.append(x[idx_n:idx_n+graph_size[i],:])\n","        idx_n += graph_size[i]\n","        idx_m += adj[i].nnz\n","\n","    return adj, features, edge_features, graph_labels\n","\n","def normalize_adjacency(A):\n","    \"\"\"\n","    Function that normalizes an adjacency matrix\n","    \"\"\"\n","    n = A.shape[0]\n","    A = A + sp.identity(n)\n","    degs = A.dot(np.ones(n))\n","    inv_degs = np.power(degs, -1)\n","    D = sp.diags(inv_degs)\n","    A_normalized = D.dot(A)\n","\n","    return A_normalized\n","\n","def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n","    \"\"\"\n","    Function that converts a Scipy sparse matrix to a sparse Torch tensor\n","    \"\"\"\n","    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n","    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n","    values = torch.from_numpy(sparse_mx.data)\n","    shape = torch.Size(sparse_mx.shape)\n","    return torch.sparse.FloatTensor(indices, values, shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155608,"status":"ok","timestamp":1671660885674,"user":{"displayName":"Calvin GALAGAIN","userId":"00831497643848271461"},"user_tz":-60},"id":"iOBQia_tDMru"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001 loss_train: 0.6322 acc_train: 0.6605 time: 152.4762s\n","Epoch: 006 loss_train: 0.5391 acc_train: 0.7231 time: 141.0419s\n","Epoch: 011 loss_train: 0.5300 acc_train: 0.7205 time: 137.5384s\n","Epoch: 016 loss_train: 0.5124 acc_train: 0.7408 time: 142.0492s\n","Epoch: 021 loss_train: 0.5024 acc_train: 0.7545 time: 143.4890s\n","Epoch: 026 loss_train: 0.4858 acc_train: 0.7579 time: 143.4900s\n","Epoch: 031 loss_train: 0.4781 acc_train: 0.7601 time: 148.8408s\n","Epoch: 036 loss_train: 0.4606 acc_train: 0.7716 time: 144.7551s\n","Epoch: 041 loss_train: 0.4520 acc_train: 0.7734 time: 144.0813s\n","Epoch: 046 loss_train: 0.4309 acc_train: 0.7882 time: 143.5334s\n","loss_test: 0.4733 acc_test: 0.7807 time: 156.7385s\n"]}],"source":["\"\"\"\n","Learning on Sets / Learning with Proteins - ALTEGRAD - Dec 2022\n","\"\"\"\n","\n","import time\n","import numpy as np\n","import scipy.sparse as sp\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","\n","from sklearn.model_selection import train_test_split\n","\n","# from utils import load_data, normalize_adjacency, sparse_mx_to_torch_sparse_tensor\n","# from model import GNN\n","\n","# Load graphs\n","adj, features, edge_features, y = load_data() \n","\n","# Normalize adjacency matrices\n","adj = [normalize_adjacency(A) for A in adj]\n","\n","# Split data into training and test sets\n","adj_train, adj_test, features_train, features_test, y_train, y_test = train_test_split(adj, features, y, test_size=0.1)\n","\n","# Initialize device\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# Hyperparameters\n","epochs = 50\n","batch_size = 64\n","n_hidden = 64\n","n_input = 23\n","dropout = 0.2\n","learning_rate = 0.001\n","n_class = 2\n","\n","# Compute number of training and test samples\n","N_train = len(adj_train)\n","N_test = len(adj_test)\n","\n","# Initializes model and optimizer\n","model = GNN(n_input, n_hidden, dropout, n_class).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","loss_function = nn.CrossEntropyLoss()\n","\n","# Train model\n","for epoch in range(epochs):\n","    t = time.time()\n","    model.train()\n","    train_loss = 0\n","    correct = 0\n","    count = 0\n","    # Iterate over the batches\n","    for i in range(0, N_train, batch_size):\n","        adj_batch = list()\n","        features_batch = list()\n","        idx_batch = list()\n","        y_batch = list()\n","        \n","        # Create tensors\n","        for j in range(i, min(N_train, i+batch_size)):\n","            n = adj_train[j].shape[0]\n","            adj_batch.append(adj_train[j]+sp.identity(n))\n","            features_batch.append(features_train[j])\n","            idx_batch.extend([j-i]*n)\n","            y_batch.append(y_train[j])\n","            \n","        adj_batch = sp.block_diag(adj_batch)\n","        features_batch = np.vstack(features_batch)\n","\n","        adj_batch = sparse_mx_to_torch_sparse_tensor(adj_batch).to(device)\n","        features_batch = torch.FloatTensor(features_batch).to(device)\n","        idx_batch = torch.LongTensor(idx_batch).to(device)\n","        y_batch = torch.LongTensor(y_batch).to(device)\n","        \n","        optimizer.zero_grad()\n","        output = model(features_batch, adj_batch, idx_batch)\n","        loss = loss_function(output, y_batch)\n","        train_loss += loss.item() * output.size(0)\n","        count += output.size(0)\n","        preds = output.max(1)[1].type_as(y_batch)\n","        correct += torch.sum(preds.eq(y_batch).double())\n","        loss.backward()\n","        optimizer.step()\n","    \n","    if epoch % 5 == 0:\n","        print('Epoch: {:03d}'.format(epoch+1),\n","              'loss_train: {:.4f}'.format(train_loss / count),\n","              'acc_train: {:.4f}'.format(correct / count),\n","              'time: {:.4f}s'.format(time.time() - t))\n","        \n","# Evaluate model\n","model.eval()\n","test_loss = 0\n","correct = 0\n","count = 0\n","# Iterate over the batches\n","for i in range(0, N_test, batch_size):\n","    adj_batch = list()\n","    features_batch = list()\n","    idx_batch = list()\n","    y_batch = list()\n","    \n","    # Create tensors\n","    for j in range(i, min(N_test, i+batch_size)):\n","        n = adj_test[j].shape[0]\n","        adj_batch.append(adj_test[j]+sp.identity(n))\n","        features_batch.append(features_test[j])\n","        idx_batch.extend([j-i]*n)\n","        y_batch.append(y_test[j])\n","        \n","    adj_batch = sp.block_diag(adj_batch)\n","    features_batch = np.vstack(features_batch)\n","\n","    adj_batch = sparse_mx_to_torch_sparse_tensor(adj_batch).to(device)\n","    features_batch = torch.FloatTensor(features_batch).to(device)\n","    idx_batch = torch.LongTensor(idx_batch).to(device)\n","    y_batch = torch.LongTensor(y_batch).to(device)\n","\n","    output = model(features_batch, adj_batch, idx_batch)\n","    loss = loss_function(output, y_batch)\n","    test_loss += loss.item() * output.size(0)\n","    count += output.size(0)\n","    preds = output.max(1)[1].type_as(y_batch)\n","    correct += torch.sum(preds.eq(y_batch).double())\n","\n","print('loss_test: {:.4f}'.format(test_loss / count),\n","      'acc_test: {:.4f}'.format(correct / count),\n","      'time: {:.4f}s'.format(time.time() - t))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO4IAmdQuwAFduSW/EKAdyE","mount_file_id":"1jpKDYl3Or8rJmrC8sHKrAr-iuBBMdhmz","name":"","version":""},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3aec62271aee41b08a463fe6c4b04e2b":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_52583bc37e8948ad92a99b4cc1b11173","msg_id":"","outputs":[{"data":{"text/html":"\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003eReading PDB file...         \u003cspan style=\"color: #729c1f; text-decoration-color: #729c1f\"\u003e━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u003c/span\u003e \u003cspan style=\"color: #800080; text-decoration-color: #800080\"\u003e100%\u003c/span\u003e \u003cspan style=\"color: #008080; text-decoration-color: #008080\"\u003e0:00:00\u003c/span\u003e\nProcessing PDB dataframe... \u003cspan style=\"color: #729c1f; text-decoration-color: #729c1f\"\u003e━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u003c/span\u003e \u003cspan style=\"color: #800080; text-decoration-color: #800080\"\u003e100%\u003c/span\u003e \u003cspan style=\"color: #008080; text-decoration-color: #008080\"\u003e0:00:00\u003c/span\u003e\nInitializing graph...       \u003cspan style=\"color: #729c1f; text-decoration-color: #729c1f\"\u003e━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u003c/span\u003e \u003cspan style=\"color: #800080; text-decoration-color: #800080\"\u003e100%\u003c/span\u003e \u003cspan style=\"color: #008080; text-decoration-color: #008080\"\u003e0:00:00\u003c/span\u003e\nConstructing edges...       \u003cspan style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\"\u003e━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u003c/span\u003e \u003cspan style=\"color: #800080; text-decoration-color: #800080\"\u003e  0%\u003c/span\u003e \u003cspan style=\"color: #008080; text-decoration-color: #008080\"\u003e-:--:--\u003c/span\u003e\n\u003c/pre\u003e\n","text/plain":"Reading PDB file...         \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\nProcessing PDB dataframe... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\nInitializing graph...       \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\nConstructing edges...       \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"52583bc37e8948ad92a99b4cc1b11173":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}